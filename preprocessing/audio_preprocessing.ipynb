{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e962e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\egorv\\Desktop\\BProj\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import scipy.signal as signal\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import sounddevice as sd\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "import pandas\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import Wav2Vec2Model, HubertModel\n",
    "import torch.optim as optim\n",
    "#c:/Users/egorv/Desktop/BProj\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"code\" / \"experiments\" / \"data\" / \"ASVSpoof2019\"\n",
    "TARGET_SEC = 4.0\n",
    "TARGET_LEN = int(16000 * TARGET_SEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "966d0ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASVSpoofDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, flac_dir, labels_path):\n",
    "        \"\"\"\n",
    "        Returns all the directory where the flac_files are located, returns the files itself,\n",
    "        returns the dataset with filenames, targets, speaker ID, and type attack ID.\n",
    "        Also returns the list of filenames, and target dictionary\n",
    "        \"\"\"\n",
    "        self.flac_dir = flac_dir\n",
    "        self.files = sorted(Path(flac_dir).glob(\"*.flac\"))\n",
    "        self.labels_df = pandas.read_csv(labels_path, sep=r\"\\s+\", header=None)\n",
    "        self.file_names = self.labels_df[1]\n",
    "        self.target = dict(zip(self.labels_df[1], self.labels_df[4]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        file_path = self.files[idx]\n",
    "\n",
    "        x, _ = librosa.load(file_path, sr=16000)\n",
    "        x = self.normalize_duration(x)\n",
    "\n",
    "        file_name = file_path.stem\n",
    "        target_str = self.target.get(file_name)\n",
    "\n",
    "        y = 1 if target_str == 'bonafide' else 0\n",
    "        return torch.from_numpy(x).float(), torch.tensor(y).long()\n",
    "\n",
    "    def normalize_duration(self, x):\n",
    "        TARGET_SEC = 4.0\n",
    "        TARGET_LEN = int(16000 * TARGET_SEC)\n",
    "        \n",
    "        cur_len = len(x)\n",
    "\n",
    "        if cur_len > TARGET_LEN:\n",
    "            start = np.random.randint(0, cur_len - TARGET_LEN)\n",
    "            return x[start:start+TARGET_LEN]\n",
    "        \n",
    "        if cur_len < TARGET_LEN:\n",
    "            pad = TARGET_LEN - cur_len\n",
    "            return np.pad(x, (0, pad), mode='constant')\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c8ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.wav2vec2 = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "        self.hubert = HubertModel.from_pretrained(\"facebook/hubert-base-ls960\")\n",
    "        combined_dim = self.wav2vec2.config.hidden_size + self.hubert.config.hidden_size\n",
    "\n",
    "        self.classifier = nn.Linear(combined_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        w2v_out = self.wav2vec2(x).last_hidden_state.mean(dim=1)\n",
    "        hubert_out = self.hubert(x).last_hidden_state.mean(dim=1)\n",
    "\n",
    "        combined = torch.cat((w2v_out, hubert_out), dim=1)\n",
    "\n",
    "        return self.classifier(combined)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df704ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer, train_loader, optimizer, loss_fn, model, device, log_every=50):\n",
    "    running_loss = 0.0\n",
    "    total_loss = 0.0\n",
    "    model.train(True)\n",
    "\n",
    "    for batch_idx, (audios, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        audios, labels = audios.to(device), labels.to(device)\n",
    "        outputs = model(audios)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_val = loss.item()\n",
    "        total_loss += loss_val\n",
    "        running_loss += loss_val\n",
    "\n",
    "        if (batch_idx + 1) % log_every == 0:\n",
    "            avg_50 = running_loss / log_every\n",
    "            tb_x = epoch_index * len(train_loader) + batch_idx + 1\n",
    "            tb_writer.add_scalar(\"Loss/Train\", avg_50, tb_x)\n",
    "            running_loss = 0.0\n",
    "\n",
    "    epoch_avg = total_loss / max(1, len(train_loader))\n",
    "    tb_writer.add_scalar(\"Loss/Train_epoch\", epoch_avg, epoch_index + 1)\n",
    "    tb_writer.flush()\n",
    "    return epoch_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20b3dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flac_dir = (DATA_DIR/ \"LA\" / \"ASVSpoof2019_LA_train\" / \"flac\")\n",
    "labels_file = DATA_DIR / \"LA\" / \"ASVspoof2019_LA_cm_protocols\" / \"ASVspoof2019.LA.cm.train.trn.txt\"\n",
    "\n",
    "flac_dataset = ASVSpoofDataset(train_flac_dir, labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91070a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "indices = list(range(len(flac_dataset)))\n",
    "\n",
    "train_split, temp_split = train_test_split(indices, train_size=0.8, shuffle=True, random_state=10)\n",
    "val_split, test_split = train_test_split(temp_split, train_size=0.5, random_state=10)\n",
    "\n",
    "train_subset = Subset(flac_dataset, train_split)\n",
    "val_subset = Subset(flac_dataset, val_split)\n",
    "test_subset = Subset(flac_dataset, test_split)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=16, num_workers=0, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=16, num_workers=0, shuffle=False)\n",
    "test_loader = DataLoader(test_subset, batch_size=16, num_workers=0, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d531ac31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_loader) = 1269\n",
      "len(val_loader)   = 159\n"
     ]
    }
   ],
   "source": [
    "print(\"len(train_loader) =\", len(train_loader))\n",
    "print(\"len(val_loader)   =\", len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0083f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 211/211 [00:00<00:00, 1290.48it/s, Materializing param=masked_spec_embed]                                            \n",
      "Wav2Vec2Model LOAD REPORT from: facebook/wav2vec2-base\n",
      "Key                          | Status     |  | \n",
      "-----------------------------+------------+--+-\n",
      "quantizer.weight_proj.bias   | UNEXPECTED |  | \n",
      "quantizer.codevectors        | UNEXPECTED |  | \n",
      "project_hid.weight           | UNEXPECTED |  | \n",
      "quantizer.weight_proj.weight | UNEXPECTED |  | \n",
      "project_q.weight             | UNEXPECTED |  | \n",
      "project_hid.bias             | UNEXPECTED |  | \n",
      "project_q.bias               | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 211/211 [00:00<00:00, 833.19it/s, Materializing param=masked_spec_embed]                                            \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = EnsembleModel().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b13d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing logs to: C:\\Users\\egorv\\Desktop\\BProj\\runs\\fashion_trainer_20260128_203238\n",
      "len(train_loader) = 1269\n",
      "len(val_loader)   = 159\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "project_root = Path(r\"C:\\Users\\egorv\\Desktop\\BProj\")\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "log_dir = project_root / \"runs\" / f\"fashion_trainer_{timestamp}\"\n",
    "writer = SummaryWriter(str(log_dir))\n",
    "\n",
    "print(\"Writing logs to:\", log_dir)\n",
    "\n",
    "print(\"len(train_loader) =\", len(train_loader))\n",
    "print(\"len(val_loader)   =\", len(val_loader))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch, writer, train_loader, optimizer, criterion, model, device)\n",
    "    avg_loss_f = float(avg_loss)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(val_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = criterion(voutputs, vlabels)\n",
    "            running_vloss += vloss.item()\n",
    "\n",
    "    avg_vloss = running_vloss / (i+1)\n",
    "    avg_vloss_f = float(avg_vloss)\n",
    "\n",
    "    print('LOSS train {} valid {}'.format(avg_loss_f, avg_vloss_f))\n",
    "\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss_f, 'Validation' : avg_vloss_f },\n",
    "                    epoch + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = project_root / f\"model_{timestamp}_{epoch}.pt\"\n",
    "        torch.save(model.state_dict(), str(model_path))\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15907211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote to: C:\\Users\\egorv\\Desktop\\BProj\\runs\\debug_tb\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pathlib import Path\n",
    "\n",
    "log_dir = Path(r\"C:\\Users\\egorv\\Desktop\\BProj\\runs\\debug_tb\")\n",
    "w = SummaryWriter(str(log_dir))\n",
    "\n",
    "w.add_scalar(\"debug/alive\", 1.0, 0)\n",
    "w.flush()\n",
    "w.close()\n",
    "\n",
    "print(\"Wrote to:\", log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4097f93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
